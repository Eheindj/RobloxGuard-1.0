{
  "name": "safeRLHF",

  "model_path": "Roblox/RoGuard-1.0",
  "base_model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "max_output_tokens": 100,

  "eval_prompt": "prompts/safeRLHF.txt",
  "llm_output_field": "Response Safety",
  "llm_flagged_value": "unsafe",

  "eval_dataset": "PKU-Alignment/PKU-SafeRLHF",
  "eval_label_field": "is_safe",
  "eval_flagged_value": "unsafe",

  "output_file": "outputs/safeRLHF.csv"
}
